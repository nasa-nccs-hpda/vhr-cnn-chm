{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07d93a0c-c5c8-4411-b3dd-539e127fa05d",
   "metadata": {},
   "source": [
    "# Regression CNN Pipeline for VHR CHM\n",
    "\n",
    "This notebook is used to illustrate the full development lifecycle of a regression Convolutional Neural Network (CNN) to produce Canopy Height models (CHM) from very high-resolution data. The data used in this work comes from WorldView imagery, while the labels are taken from highly preprocessed ICESat ATL08 points generated by Montesano et al. The initial study area is Senegal.\n",
    "\n",
    "Science Question:\n",
    "- Can we generate VHR CHM models using ICESat-2 points as training data and CNNs as the regression algorithm?\n",
    "\n",
    "Possible Research Directions:\n",
    "- Datacube format (e.g. optical, land cover, DEMs, veg. indices, resolution, photon-level data)\n",
    "- Algorithm (e.g. random forest, neural network, 2d-CNN, 3d-CNN)\n",
    "- Training data (e.g. tile size, matching training data, transfer learning for more-than-regional)\n",
    "\n",
    "Challenges:\n",
    "- Resolution (e.g. ICESat 30m vs WorldView 2m)\n",
    "- CNNs were designed for classification, we are making in-house modifications for regression\n",
    "- Forest patch vs. sparse forest patch\n",
    "\n",
    "Let's discuss and have some fun!\n",
    "\n",
    "## Data Science Development Phases from a Computer Science Perspective\n",
    "\n",
    "- Data Gathering\n",
    "- Exploratory Data Analysis\n",
    "- Preprocessing\n",
    "- Training\n",
    "- Inference\n",
    "- Validation\n",
    "\n",
    "## 1. Data Gathering\n",
    "\n",
    "Below we illustrated the ATL08 points available, together with the footprint of the World View imagery available for the selected study area (future, gather from Maggie). Some of the local filtering is perform with the following code:\n",
    "\n",
    "```bash\n",
    "pdsh -g ilab,forest do_extract_filter_atl08.sh \\\"2018 2019 2020 2021\\\" /att/nobackup/pmontesa/userfs02/data/icesat2/list_atl08.005 senegal\n",
    "\n",
    "pdsh -g ilab,forest do_extract_filter_atl08.sh \\\"2018 2019 2020 2021\\\" /att/nobackup/pmontesa/userfs02/data/icesat2/list_atl08.005 senegal_no_filt\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c7ccb61-e10f-455c-9ed0-6b8d86a48424",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import omegaconf\n",
    "from glob import glob\n",
    "from pathlib import Path\n",
    "\n",
    "sys.path.append('/adapt/nobackup/people/jacaraba/development/tensorflow-caney')\n",
    "sys.path.append('/adapt/nobackup/people/jacaraba/development/vhr-cnn-chm')\n",
    "sys.path.append('/home/pmontesa/code/icesat2')\n",
    "\n",
    "import rasterio\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "from vhr_cnn_chm.model.geoscitools import maplib, atl08lib\n",
    "from vhr_cnn_chm.model.cnn_regression_pipeline import CNNRegressionPipeline\n",
    "from shapely.geometry import Point\n",
    "from rasterio.plot import show\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a0148ce-cb5d-4973-80f2-070ba1289fb5",
   "metadata": {},
   "source": [
    "### 1.1 Define General Variables\n",
    "\n",
    "To match the CLI development script, we use omegaconf to structure the variables required for this work. Ideally, this would be done from a configuration file for the CLI script. The main idea of the CLI script is to avoid falling into the timeout issues encountered in JupyterHub, including the use of more than 1-GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7fd40a5-c321-4603-bf8e-9258a493e3f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# General configurations\n",
    "omega_conf_string = \"\"\"\n",
    "# General CRS to leverage across the data\n",
    "general_crs: \"EPSG:32628\"\n",
    "\n",
    "# ATL08 configurations\n",
    "atl08_dir: '/adapt/nobackup/people/pmontesa/userfs02/data/icesat2/atl08.005/senegal'\n",
    "chm_footprints_fn: '/adapt/nobackup/people/pmontesa/chm_work/hrsi_chm_senegal/merge.shp'\n",
    "\n",
    "# ATL08 available data\n",
    "atl08_start_year: 2018\n",
    "atl08_end_year: 2022\n",
    "\n",
    "# WorldView available data\n",
    "wv_data_regex:\n",
    "  - '/adapt/nobackup/people/mwooten3/Senegal_LCLUC/VHR/CAS/M1BS/*.tif'\n",
    "  - '/adapt/nobackup/people/mwooten3/Senegal_LCLUC/VHR/ETZ/M1BS/*.tif'\n",
    "  - '/adapt/nobackup/people/mwooten3/Senegal_LCLUC/VHR/SRV/M1BS/*.tif'\n",
    "\n",
    "# Output directories to store data\n",
    "intersection_output_dir: '/adapt/nobackup/projects/ilab/projects/Senegal/CNN_CHM/v1/intersection_metadata_evhrtoa'\n",
    "tiles_output_dir: '/adapt/nobackup/projects/ilab/projects/Senegal/CNN_CHM/v1/intersection_tiles_evhrtoa'\n",
    "\n",
    "# Data extraction metadata\n",
    "tile_buffer: 520\n",
    "\"\"\"\n",
    "conf = omegaconf.OmegaConf.create(omega_conf_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "466ca416-8e09-4d34-b43c-37cd3c908c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "omegaconf.OmegaConf.to_yaml(conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4559a2aa-c441-4ca9-ab07-2f8452b1e216",
   "metadata": {},
   "source": [
    "### 1.2 Build ATL08 geodataframe from extracted CSVs\n",
    "\n",
    "These CSVs were heavily filtered with land-cover specific thresholds for h_can (canopy height)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f8f6e1a-a6ee-481a-8b45-6db0e793f016",
   "metadata": {},
   "outputs": [],
   "source": [
    "atl08_gdf = []\n",
    "for year in range(conf.atl08_start_year, conf.atl08_end_year):\n",
    "    atl08_gdf.append(atl08lib.atl08_io(conf.atl08_dir, str(year), do_pickle=False))\n",
    "atl08_gdf = pd.concat(atl08_gdf)\n",
    "atl08_gdf.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84695247-8f27-46e7-aef0-5b5bdda01fca",
   "metadata": {},
   "source": [
    "### 1.3 Make an interactive map to view the heavily filtered set of ATL08 obs.\n",
    "\n",
    "Make sure to set SAMP_FRAC so you dont map all the points. This is the footprints vector of the ~2m HRSI DSM-derived \"CHM\" data we are playing with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b091dd86-8272-41ba-96a3-d4131d2d333d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNCOMMENT if you want to visualize the points\n",
    "# %%time\n",
    "# SAMP_FRAC=0.25\n",
    "# maplib.MAP_ATL08_FOLIUM(atl08_gdf.sample(frac=SAMP_FRAC), MAP_COL='h_can', DO_NIGHT=False, LAYER_FN=conf.chm_footprints_fn, RADIUS=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef4a8883-960d-4163-8df8-47b8b07b531e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "SAMP_FRAC=0.25\n",
    "maplib.MAP_ATL08_FOLIUM(atl08_gdf.sample(frac=SAMP_FRAC), MAP_COL='h_can', DO_NIGHT=False, LAYER_FN=conf.chm_footprints_fn, RADIUS=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96e92269-a1c8-4177-b467-d03cce4e3f0a",
   "metadata": {},
   "source": [
    "## 2. Data Preprocessing\n",
    "\n",
    "In this section we gather the training data and EVHR + ICESat intersections. We start from the already generated EVHR scenes, to then find the intersections of the above mentioned points.\n",
    "\n",
    "100 x 12 m wide\n",
    "\n",
    "Question here:\n",
    "- How do we select the tile size to choose from?\n",
    "- What are the benefits?\n",
    "- What are the downsides or consequences from these selections?\n",
    "\n",
    "We have created a pipeline object to ease the development regardless of the environment (e.g. CLI, JH), which we initialize below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "141fd893-c571-4b4a-806b-8e2b278c5ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_pipeline = CNNRegressionPipeline(conf)\n",
    "dir(cnn_pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8a3cbfa-f0e6-4ffa-b1fd-b64d419e1a08",
   "metadata": {},
   "source": [
    "### 2.1 Read ATL08 points\n",
    "\n",
    "Here we read ATL08 points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ccfef51-e443-4324-a181-f7186d85bb05",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "cnn_pipeline.atl08_gdf = cnn_pipeline.get_atl08_gdf(\n",
    "    conf.atl08_dir,\n",
    "    conf.atl08_start_year,\n",
    "    conf.atl08_end_year,\n",
    "    conf.general_crs\n",
    ")\n",
    "print(f'Load ATL08 GDF files, {cnn_pipeline.atl08_gdf.shape[0]} rows.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6ef89ea-469a-468e-8a0f-57d80a68d1f5",
   "metadata": {},
   "source": [
    "## 2.2 Read and Filter WorldView Imagery\n",
    "\n",
    "We go straigth to the data, We tried reading from the footprints database, but the polygons were not good enough to find intersections between the EVHR output and the ATL08 data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc4289be-c6d2-4435-a78b-f69dbc8c1564",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "cnn_pipeline.wv_evhr_gdf = cnn_pipeline.get_wv_evhr_gdf(\n",
    "    conf.wv_data_regex, crs=conf.general_crs)\n",
    "print(f'Load WorldView GDF, {wv_evhr_gdf.shape[0]} rows.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e573e724-761f-4997-b11e-5e4b716b848f",
   "metadata": {},
   "source": [
    "Filter the WorldView data based on the years available from ICESat-2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0249ab0a-b284-4212-9795-5341445b457f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "cnn_pipeline.wv_evhr_gdf = cnn_pipeline.filter_gdf_by_list(\n",
    "    cnn_pipeline.wv_evhr_gdf, 'acq_year', list(range(conf.atl08_start_year, conf.atl08_end_year)))\n",
    "print(f'Filter WorldView GDF by year, {cnn_pipeline.wv_evhr_gdf.shape[0]} rows.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "784effd1-cf36-44a0-a999-c436f3cd6f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_pipeline.wv_evhr_gdf.plot(color='white', edgecolor='black')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc6c45b3-2366-4d48-8579-428cfbf565ae",
   "metadata": {},
   "source": [
    "## 2.3 Get the Intersection of both datasets\n",
    "\n",
    "Get the intersection of the two GDBs, and output geopackage files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "666b7314-a80f-4406-bbd6-84a9bd409280",
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNCOMMENT if you want to extract all world view files that have ATL08 points\n",
    "# this step only needs to be done once\n",
    "# cnn_pipeline.get_point_in_polygon_by_scene()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b2e3633-1f2b-4c53-8d11-e474222c281a",
   "metadata": {},
   "source": [
    "Lets visualize some of that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "845d1e67-1abf-48dc-9cf5-6a4bdf9fe3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNCOMMENT if you want to visualize some of the WorldView ICESAT-2 intersections\n",
    "# wv_data_dir = '/adapt/nobackup/people/mwooten3/Senegal_LCLUC/VHR/CAS/M1BS'\n",
    "# intersection_gpkg_filenames = glob(os.path.join(conf.intersection_output_dir, f'*/*.gpkg'))\n",
    "# print(f'{len(intersection_gpkg_filenames)} intersected WorldView scenes')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cb0e730-c181-41c4-88f0-c472b50454b9",
   "metadata": {},
   "source": [
    "### 2.4 WorldView and ICESat Intersection Analysis\n",
    "\n",
    "We now know the locations of the ICESat points, we can proceed to visualize any intersection points within the already generated Senegal EVHR scenes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c59c234-d26f-436c-ae03-283e7fcf4163",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "for intersected_atl08_filename in intersection_gpkg_filenames[:5]:\n",
    "    \n",
    "    wv_filename = os.path.join(wv_data_dir, f'{Path(intersected_atl08_filename).stem}.tif')\n",
    "    \n",
    "    raster_data = rasterio.open(wv_filename)\n",
    "    atl08_data = gpd.read_file(intersected_atl08_filename, layer='ATL08_WorldView')\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(20,15))\n",
    "    \n",
    "    # transform rasterio plot to real world coords\n",
    "    extent=[raster_data.bounds[0], raster_data.bounds[2], raster_data.bounds[1], raster_data.bounds[3]]\n",
    "    ax = rasterio.plot.show(raster_data, extent=extent, ax=ax, cmap='pink')\n",
    "    atl08_data.plot(ax=ax)\n",
    "\n",
    "    plt.title(f'{wv_filename}, {atl08_data.shape[0]}')\n",
    "    plt.show()\n",
    "\"\"\"\n",
    "# UNCOMMENT if you want to visualize some of the WorldView ICESAT-2 intersections"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56910f98-f928-4ea7-ba00-a7e8e03472ac",
   "metadata": {},
   "source": [
    "### 2.5 Extract Tiles Matching ICESat-2 extent\n",
    "\n",
    "In this section we extract training and validation tiles matching the desired extent. Let's look at the script."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d22d84d-92c5-4f44-bc47-5a64f36cef09",
   "metadata": {},
   "source": [
    "## 3. Training the CNN Model\n",
    "\n",
    "In this section we proceed to train the CNN model.\n",
    "\n",
    "## 3.1 CNN Model Explained (what needs to change for regression?)\n",
    "\n",
    "Common 2D CNN models rely on continuous data. Generally they are used for classification problems, but we can modify the architectures to apply to regression. Let's walk through how to define a network, or how to reuse someone else network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de5ac1d4-8c5a-4e54-9c67-71520faef240",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import logging\n",
    "import fiona\n",
    "import rasterio\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import rioxarray as rxr\n",
    "import geopandas as gpd\n",
    "import shapely.speedups\n",
    "from omegaconf.listconfig import ListConfig\n",
    "from multiprocessing import Pool, Lock, cpu_count\n",
    "\n",
    "import cuspatial\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from shapely.geometry import box\n",
    "from skimage.transform import resize\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "shapely.speedups.enable()\n",
    "\n",
    "from vhr_cnn_chm.model.geoscitools.atl08lib import atl08_io\n",
    "from vhr_cnn_chm.model.cnn_model import get_2d_cnn_tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebb805e2-41e2-4996-bad1-486c4e679f80",
   "metadata": {},
   "source": [
    "Let's take a look at some of these tiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2bcf2ea-9d93-47ee-b145-ec89730787c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/adapt/nobackup/projects/ilab/projects/Senegal/CNN_CHM/tiles_cas/*.tif'\n",
    "data_filenames = glob.glob(data_dir)\n",
    "print(f'{len(data_filenames)} extracted data tiles')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3203fb0-08d9-4e49-a7c0-00d2cddd50b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for tile in data_filenames[:3]:\n",
    "    print(tile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db7eaa1-5d8e-4771-b045-8ac935ec5ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_pipeline = CNNRegressionPipeline(conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99366bb2-3a0e-4055-8e1e-ed91bc57fdd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO:\n",
    "# - Consider adding the spatial location as a band\n",
    "\n",
    "# get data and labels\n",
    "data_array, labels_df = cnn_pipeline.get_data_labels(data_filenames[:100])\n",
    "print(data_array.shape, labels_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ff8954-f8bf-4562-8d7d-58040a5eecd4",
   "metadata": {},
   "source": [
    "### 3.2 Normalization of the Data\n",
    "\n",
    "CNNs are distance based algorithms. If we do not normalize or standardize the data, the algorithm will be prone to overfitting in the presence of huge variations in the distribution of the data. There are several techniques we can use for this. The simplest one for initial testing is the normalization. When fine-tuning the model, we proceed to standardize based on the data mean and standard deviation.\n",
    "\n",
    "Question for the group:\n",
    "- Do we normalize the heigth as well? (heigth meaning the labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6cbbf79-2586-49dd-9689-ba3c8736e9a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_array = data_array / 10000.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "800f8fc9-edac-46c2-be33-fe47232cf01b",
   "metadata": {},
   "source": [
    "Now we split our dataset, we need a training dataset and a validation/testing dataset. The validation dataset is of great importance during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0426a422-3242-4ee8-bb0d-9c3d845c9ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data in training and validation\n",
    "split = train_test_split(labels_df, data_array, test_size=0.25, random_state=42)\n",
    "(trainAttrY, testAttrY, trainImagesX, testImagesX) = split\n",
    "print(trainAttrY.shape, testAttrY.shape, trainImagesX.shape, testImagesX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd6cfd69-0e9a-4e86-a066-f15de14cbdb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import BatchNormalization, Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D, Activation, Dropout\n",
    "from tensorflow.keras.layers import Dense, Flatten, Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9804e510-8e20-4404-b204-6b7999e65fdd",
   "metadata": {},
   "source": [
    "Lets learn how to define a neural network, and add convolutional components to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd01fa2-dbbf-4125-8ad3-b7db758526e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_2d_cnn_tf(input_size=(256, 256, 3), filters=(16, 32, 64), regression=False, chanDim=-1):\n",
    "\n",
    "    # define the model input\n",
    "    inputs = Input(shape=input_size)\n",
    "\n",
    "    # loop over the number of filters\n",
    "    for (i, f) in enumerate(filters):\n",
    "        \n",
    "        # if this is the first CONV layer, initialize with input\n",
    "        if i == 0:\n",
    "            x = inputs\n",
    "\n",
    "        # CONV => RELU => BN => POOL\n",
    "        x = Conv2D(f, (3, 3), padding=\"same\")(x)\n",
    "        x = Activation(\"relu\")(x)\n",
    "        x = BatchNormalization(axis=chanDim)(x)\n",
    "        x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "    # flatten the volume, then FC => RELU => BN => DROPOUT\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(32)(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = BatchNormalization(axis=chanDim)(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "\n",
    "    x = Dense(16)(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = BatchNormalization(axis=chanDim)(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "\n",
    "    # apply another FC layer, this one to match the number of nodes\n",
    "    # coming out of the MLP\n",
    "    x = Dense(4)(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "\n",
    "    # regression execution\n",
    "    if regression:\n",
    "        x = Dense(1, activation=\"linear\")(x)\n",
    "\n",
    "    # construct the CNN\n",
    "    model = Model(inputs=inputs, outputs=x, name=\"SimpleRegression_2dCNN\")\n",
    "\n",
    "    # return the CNN\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ff77c6-b676-4b37-a4a3-a789e345717f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_2d_cnn_tf(\n",
    "    input_size=(128, 128, 8), filters=(16, 32, 64, 128, 256, 512, 1024), regression=True)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43926e08-ca71-4871-bfa5-47856c96d63a",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = Adam(learning_rate=1e-3, decay=1e-3 / 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "816b8ad0-546c-4a00-9a70-dc67f5a8411a",
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    tf.keras.callbacks.ModelCheckpoint(\n",
    "        save_best_only=True, mode='min', monitor='val_loss',\n",
    "        filepath='/adapt/nobackup/projects/ilab/projects/Senegal/CNN_CHM/model/test-{epoch:02d}-{val_loss:.2f}.hdf5'),\n",
    "    tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=4),\n",
    "    tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "]\n",
    "\n",
    "metrics = [\n",
    "    tf.keras.metrics.MeanSquaredError(),\n",
    "    tf.keras.metrics.RootMeanSquaredError(),\n",
    "    tf.keras.metrics.MeanAbsoluteError(),\n",
    "    tf.keras.metrics.MeanAbsolutePercentageError(),\n",
    "    tf.keras.metrics.CosineSimilarity(axis=1)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e37cce-f3dc-4cab-99b5-bd9b63af5dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss=\"mean_absolute_percentage_error\", optimizer=opt,\n",
    "    metrics=metrics\n",
    ")\n",
    "\n",
    "# train the model\n",
    "model.fit(\n",
    "    x=trainImagesX, y=trainAttrY, \n",
    "    validation_data=(testImagesX, testAttrY),\n",
    "    epochs=10,#6000,\n",
    "    batch_size=32,\n",
    "    callbacks=callbacks\n",
    ")\n",
    "\n",
    "ypred = model.predict(testImagesX)\n",
    "print(model.evaluate(testImagesX, testAttrY))\n",
    "\n",
    "print(\"MSE: %.4f\" % mean_squared_error(testAttrY, ypred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0df6cc29-205b-46d4-a4e2-82a40f8579c7",
   "metadata": {},
   "source": [
    "## Lets visualize some of these feature maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a052145-4173-48fa-ac21-1d16fcc2e59e",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_outputs = [layer.output for layer in model.layers]\n",
    "layer_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd1cd95-8f28-41cf-8677-9500a324d09f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tile = rxr.open_rasterio(data_filenames[0]).values\n",
    "tile = np.moveaxis(tile, 0, -1)\n",
    "tile = resize(tile, (128, 128))\n",
    "tile /= 10000.0\n",
    "tile = np.expand_dims(tile, 0)\n",
    "tile.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c2282e-a3f6-44c3-b860-8727eff0f0ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = model.layers\n",
    "filters, biases = model.layers[1].get_weights()\n",
    "print(layer[1].name, filters.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9675a562-047b-4220-9bfc-1ac388a53037",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f8f4748-7d16-4f58-a46d-7f185f9b130b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig1 = plt.figure(figsize=(8, 12))\n",
    "columns = 4\n",
    "rows = 4\n",
    "n_filters = columns * rows\n",
    "for i in range(1, n_filters + 1):\n",
    "    f = filters[:, :, :, i-1]\n",
    "    fig1 =plt.subplot(rows, columns, i)\n",
    "    fig1.set_xticks([])  #Turn off axis\n",
    "    fig1.set_yticks([])\n",
    "    plt.imshow(f[:, :, 0], cmap='gray') #Show only the filters from 0th channel (R)\n",
    "    #ix += 1\n",
    "plt.show()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ae91cd-4385-4863-825c-17d66a0f3d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_layer_index = [1, 5, 9]  #TO define a shorter model\n",
    "outputs = [model.layers[i].output for i in conv_layer_index]\n",
    "model_short = Model(inputs=model.inputs, outputs=outputs)\n",
    "print(model_short.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffbffca1-f9ce-48bf-bb5b-93138e7f6823",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_output = model_short.predict(tile)\n",
    "feature_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e182dbf4-8884-4afb-bc7d-3fd4840fc899",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_names = [layer.name for layer in model.layers]\n",
    "layer_outputs = [layer.output for layer in model.layers]\n",
    "layer_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7406cdf-d338-42b0-a4df-932278156b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_map_model = tf.keras.models.Model(inputs=model.inputs, outputs=layer_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a78d71cc-6632-4ee5-a6ed-7cbdb993e0dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_maps = feature_map_model.predict(tile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4543c01-fcde-4507-871c-25d9826f8974",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer_name, feature_map in zip(layer_names, feature_maps):\n",
    "    if len(feature_map.shape) == 4:\n",
    "        k = feature_map.shape[-1]  \n",
    "        size=feature_map.shape[1]\n",
    "        for i in range(k):\n",
    "            feature_image = feature_map[0, :, :, i]\n",
    "            feature_image -= feature_image.mean()\n",
    "            feature_image /= feature_image.std ()\n",
    "            feature_image *=  64\n",
    "            feature_image += 128\n",
    "            feature_image = np.clip(feature_image, 0, 255).astype('uint8')\n",
    "            print(feature_image.shape, \n",
    "            #image_belt[:, i * size : (i + 1) * size] = feature_image   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d4d951d-41f4-43fb-b662-b58e361d95a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "scale = 20. / k\n",
    "plt.figure( figsize=(scale * k, scale) )\n",
    "plt.title ( layer_name )\n",
    "plt.grid  ( False )\n",
    "plt.imshow( image_belt, aspect='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "796b62ba-2b59-4816-b0aa-f6a8fcf290d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
